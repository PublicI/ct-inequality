{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Inequality\n",
    "\n",
    "To get a sense of how inequality in Connecticut's cities compared nationally, we decided to look at the ratio between two benchmarks: The lowest combined income a household could earn while still breaking into the top 5 percent of household income and the highest combined income a household could earn while still falling in the bottom 20 percent. The farther apart these two numbers are, proportionally, the greater the gap between rich and poor.\n",
    "\n",
    "The US Census Bureau provides estimates of the numbers we need in a table titled [HOUSEHOLD INCOME QUINTILE UPPER LIMITS](https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_16_5YR_B19080&prodType=table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO.id2</th>\n",
       "      <th>GEO.display-label</th>\n",
       "      <th>Upper_Limit_Bottom_20</th>\n",
       "      <th>Lower_Limit_Top_5</th>\n",
       "      <th>respop72016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35620</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA Metro Area</td>\n",
       "      <td>25717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20275179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31080</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA Metro Area</td>\n",
       "      <td>25626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13328261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16980</td>\n",
       "      <td>Chicago-Naperville-Elgin, IL-IN-WI Metro Area</td>\n",
       "      <td>25921</td>\n",
       "      <td>245949.0</td>\n",
       "      <td>9546326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19100</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX Metro Area</td>\n",
       "      <td>28601</td>\n",
       "      <td>234781.0</td>\n",
       "      <td>7253424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26420</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX Metro Area</td>\n",
       "      <td>25785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6798010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47900</td>\n",
       "      <td>Washington-Arlington-Alexandria, DC-VA-MD-WV M...</td>\n",
       "      <td>41076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6150681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33100</td>\n",
       "      <td>Miami-Fort Lauderdale-West Palm Beach, FL Metr...</td>\n",
       "      <td>21198</td>\n",
       "      <td>221668.0</td>\n",
       "      <td>6107433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37980</td>\n",
       "      <td>Philadelphia-Camden-Wilmington, PA-NJ-DE-MD Me...</td>\n",
       "      <td>25571</td>\n",
       "      <td>246971.0</td>\n",
       "      <td>6077152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12060</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA Metro Area</td>\n",
       "      <td>26684</td>\n",
       "      <td>234699.0</td>\n",
       "      <td>5795723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14460</td>\n",
       "      <td>Boston-Cambridge-Newton, MA-NH Metro Area</td>\n",
       "      <td>31367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4805942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GEO.id2                                  GEO.display-label  \\\n",
       "0    35620   New York-Newark-Jersey City, NY-NJ-PA Metro Area   \n",
       "1    31080      Los Angeles-Long Beach-Anaheim, CA Metro Area   \n",
       "2    16980      Chicago-Naperville-Elgin, IL-IN-WI Metro Area   \n",
       "3    19100         Dallas-Fort Worth-Arlington, TX Metro Area   \n",
       "4    26420    Houston-The Woodlands-Sugar Land, TX Metro Area   \n",
       "5    47900  Washington-Arlington-Alexandria, DC-VA-MD-WV M...   \n",
       "6    33100  Miami-Fort Lauderdale-West Palm Beach, FL Metr...   \n",
       "7    37980  Philadelphia-Camden-Wilmington, PA-NJ-DE-MD Me...   \n",
       "8    12060       Atlanta-Sandy Springs-Roswell, GA Metro Area   \n",
       "9    14460          Boston-Cambridge-Newton, MA-NH Metro Area   \n",
       "\n",
       "   Upper_Limit_Bottom_20  Lower_Limit_Top_5  respop72016  \n",
       "0                  25717                NaN     20275179  \n",
       "1                  25626                NaN     13328261  \n",
       "2                  25921           245949.0      9546326  \n",
       "3                  28601           234781.0      7253424  \n",
       "4                  25785                NaN      6798010  \n",
       "5                  41076                NaN      6150681  \n",
       "6                  21198           221668.0      6107433  \n",
       "7                  25571           246971.0      6077152  \n",
       "8                  26684           234699.0      5795723  \n",
       "9                  31367                NaN      4805942  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "acs = pandas.read_csv('ACS_16_1YR_B19080-1/ACS_16_1YR_B19080.csv')\n",
    "\n",
    "## Bottom 20 cutoff is HD01_VD02, top 5 cutoff is HD01_VD06\n",
    "acs = acs[[\"GEO.id2\",\"GEO.display-label\",\"HD01_VD02\",\"HD01_VD06\"]].rename(columns = {\"HD01_VD02\":\"Upper_Limit_Bottom_20\",\"HD01_VD06\":\"Lower_Limit_Top_5\"})\n",
    "\n",
    "## We're only interested in the 100 biggest metros, so let's join the resident population table and\n",
    "## only include the largest.\n",
    "#\n",
    "## Link to census: https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=PEP_2017_PEPANNRES&prodType=table\n",
    "#\n",
    "pop_16 = pandas.read_csv(\"PEP_2017_PEPANNRES-1/PEP_2017_PEPANNRES.csv\",encoding = \"ISO-8859-1\")\n",
    "acs = acs.join(pop_16[[\"GEO.id2\",\"respop72016\"]].set_index(\"GEO.id2\"),on=\"GEO.id2\")\n",
    "acs = acs.sort_values(\"respop72016\",ascending=False).reset_index(drop=True)\n",
    "acs = acs.loc[0:99]\n",
    "\n",
    "acs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem!\n",
    "There are values missing from this table! The Census doesn't report estimates higher than $250,000. This is an example of [topcoding](link), which the Census says it does for privacy reasons. 16 of the cities in our dataset have topcoded lower limits to their top 5 percent of income earners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO.id2</th>\n",
       "      <th>GEO.display-label</th>\n",
       "      <th>Upper_Limit_Bottom_20</th>\n",
       "      <th>Lower_Limit_Top_5</th>\n",
       "      <th>respop72016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35620</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA Metro Area</td>\n",
       "      <td>25717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20275179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31080</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA Metro Area</td>\n",
       "      <td>25626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13328261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26420</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX Metro Area</td>\n",
       "      <td>25785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6798010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47900</td>\n",
       "      <td>Washington-Arlington-Alexandria, DC-VA-MD-WV M...</td>\n",
       "      <td>41076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6150681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14460</td>\n",
       "      <td>Boston-Cambridge-Newton, MA-NH Metro Area</td>\n",
       "      <td>31367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4805942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41860</td>\n",
       "      <td>San Francisco-Oakland-Hayward, CA Metro Area</td>\n",
       "      <td>36353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4699077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>42660</td>\n",
       "      <td>Seattle-Tacoma-Bellevue, WA Metro Area</td>\n",
       "      <td>34576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3802660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>41740</td>\n",
       "      <td>San Diego-Carlsbad, CA Metro Area</td>\n",
       "      <td>30265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3317200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19740</td>\n",
       "      <td>Denver-Aurora-Lakewood, CO Metro Area</td>\n",
       "      <td>32297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2851848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12580</td>\n",
       "      <td>Baltimore-Columbia-Towson, MD Metro Area</td>\n",
       "      <td>31209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2801028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12420</td>\n",
       "      <td>Austin-Round Rock, TX Metro Area</td>\n",
       "      <td>31674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2060558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>41940</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA Metro Area</td>\n",
       "      <td>41879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>25540</td>\n",
       "      <td>Hartford-West Hartford-East Hartford, CT Metro...</td>\n",
       "      <td>29378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1210075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>46520</td>\n",
       "      <td>Urban Honolulu, HI Metro Area</td>\n",
       "      <td>36055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>992761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>14860</td>\n",
       "      <td>Bridgeport-Stamford-Norwalk, CT Metro Area</td>\n",
       "      <td>34119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>949191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>37100</td>\n",
       "      <td>Oxnard-Thousand Oaks-Ventura, CA Metro Area</td>\n",
       "      <td>34721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>851096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GEO.id2                                  GEO.display-label  \\\n",
       "0     35620   New York-Newark-Jersey City, NY-NJ-PA Metro Area   \n",
       "1     31080      Los Angeles-Long Beach-Anaheim, CA Metro Area   \n",
       "4     26420    Houston-The Woodlands-Sugar Land, TX Metro Area   \n",
       "5     47900  Washington-Arlington-Alexandria, DC-VA-MD-WV M...   \n",
       "9     14460          Boston-Cambridge-Newton, MA-NH Metro Area   \n",
       "10    41860       San Francisco-Oakland-Hayward, CA Metro Area   \n",
       "14    42660             Seattle-Tacoma-Bellevue, WA Metro Area   \n",
       "16    41740                  San Diego-Carlsbad, CA Metro Area   \n",
       "18    19740              Denver-Aurora-Lakewood, CO Metro Area   \n",
       "20    12580           Baltimore-Columbia-Towson, MD Metro Area   \n",
       "30    12420                   Austin-Round Rock, TX Metro Area   \n",
       "34    41940      San Jose-Sunnyvale-Santa Clara, CA Metro Area   \n",
       "46    25540  Hartford-West Hartford-East Hartford, CT Metro...   \n",
       "53    46520                      Urban Honolulu, HI Metro Area   \n",
       "56    14860         Bridgeport-Stamford-Norwalk, CT Metro Area   \n",
       "65    37100        Oxnard-Thousand Oaks-Ventura, CA Metro Area   \n",
       "\n",
       "    Upper_Limit_Bottom_20  Lower_Limit_Top_5  respop72016  \n",
       "0                   25717                NaN     20275179  \n",
       "1                   25626                NaN     13328261  \n",
       "4                   25785                NaN      6798010  \n",
       "5                   41076                NaN      6150681  \n",
       "9                   31367                NaN      4805942  \n",
       "10                  36353                NaN      4699077  \n",
       "14                  34576                NaN      3802660  \n",
       "16                  30265                NaN      3317200  \n",
       "18                  32297                NaN      2851848  \n",
       "20                  31209                NaN      2801028  \n",
       "30                  31674                NaN      2060558  \n",
       "34                  41879                NaN      1990910  \n",
       "46                  29378                NaN      1210075  \n",
       "53                  36055                NaN       992761  \n",
       "56                  34119                NaN       949191  \n",
       "65                  34721                NaN       851096  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_coded = acs[acs[\"Lower_Limit_Top_5\"].isnull()]\n",
    "top_coded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PUMS to impute missing census aggregates\n",
    "\n",
    "Luckily, we can use the [Public Use Microdata Sample (PUMS)](https://www.census.gov/programs-surveys/acs/technical-documentation/pums.html) to estimate these values ourselves.\n",
    "\n",
    "[According to the Census](https://www.census.gov/programs-surveys/acs/technical-documentation/pums.html):\n",
    "\n",
    ">*The American Community Survey (ACS) Public Use Microdata Sample (PUMS) files are a set of untabulated records about individual people or housing units. The Census Bureau produces the PUMS files so that data users can create custom tables that are not available through pretabulated (or summary) ACS data products.*\n",
    "\n",
    "PUMS are also topcoded, but they're topcoded at $999,999 [CHECK THIS] which should let us get a good estimate of the lower cut-off of the top 5 percent of households.\n",
    "\n",
    "### 1. Correlate PUMAs to CBSAs\n",
    "\n",
    "In order to link the metro areas to the PUMS data, we need to map the GEO.id2 (FIPs codes) to the only geographic type provided in the PUMS data: Public Use Microdata Areas(PUMA). To do this we use the Missouri Census Data Center [Geographic Correspondence Engine](http://mcdc.missouri.edu/websas/geocorr14.html). Let's pull the mappings for CBSAs in all states, because we'll want them later:\n",
    "\n",
    "![shot1](Screenshots/all_states.png)\n",
    "\n",
    "We'll be mapping PUMAs to CBSAs (MSAs are a kind of CBSA):\n",
    "\n",
    "![shot2](Screenshots/mapping.png)\n",
    "\n",
    "And most PUMAs are entirely within a CBSA, but for those that aren't, Geocorr will estimate the percentage of the PUMA's population contained within that CBSA based off of 2014 measurements:\n",
    "\n",
    "![shot3](Screenshots/population.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>puma12</th>\n",
       "      <th>cbsa</th>\n",
       "      <th>stab</th>\n",
       "      <th>cbsaname15</th>\n",
       "      <th>PUMAname</th>\n",
       "      <th>pop14</th>\n",
       "      <th>afact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>00100</td>\n",
       "      <td></td>\n",
       "      <td>AL</td>\n",
       "      <td></td>\n",
       "      <td>Lauderdale, Colbert, Franklin &amp; Marion (Northe...</td>\n",
       "      <td>39326.125</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>00100</td>\n",
       "      <td>22520</td>\n",
       "      <td>AL</td>\n",
       "      <td>Florence-Muscle Shoals, AL (Metro)</td>\n",
       "      <td>Lauderdale, Colbert, Franklin &amp; Marion (Northe...</td>\n",
       "      <td>147639</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>00200</td>\n",
       "      <td>26620</td>\n",
       "      <td>AL</td>\n",
       "      <td>Huntsville, AL (Metro)</td>\n",
       "      <td>Limestone &amp; Madison (Outer) Counties--Huntsvil...</td>\n",
       "      <td>183944.849</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>00301</td>\n",
       "      <td>26620</td>\n",
       "      <td>AL</td>\n",
       "      <td>Huntsville, AL (Metro)</td>\n",
       "      <td>Huntsville (North) &amp; Madison (East) Cities</td>\n",
       "      <td>124425.297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01</td>\n",
       "      <td>00302</td>\n",
       "      <td>26620</td>\n",
       "      <td>AL</td>\n",
       "      <td>Huntsville, AL (Metro)</td>\n",
       "      <td>Huntsville City (Central &amp; South)</td>\n",
       "      <td>106218.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state puma12   cbsa stab                          cbsaname15  \\\n",
       "1    01  00100          AL                                       \n",
       "2    01  00100  22520   AL  Florence-Muscle Shoals, AL (Metro)   \n",
       "3    01  00200  26620   AL              Huntsville, AL (Metro)   \n",
       "4    01  00301  26620   AL              Huntsville, AL (Metro)   \n",
       "5    01  00302  26620   AL              Huntsville, AL (Metro)   \n",
       "\n",
       "                                            PUMAname       pop14  afact  \n",
       "1  Lauderdale, Colbert, Franklin & Marion (Northe...   39326.125  0.21   \n",
       "2  Lauderdale, Colbert, Franklin & Marion (Northe...      147639  0.79   \n",
       "3  Limestone & Madison (Outer) Counties--Huntsvil...  183944.849     1   \n",
       "4         Huntsville (North) & Madison (East) Cities  124425.297     1   \n",
       "5                  Huntsville City (Central & South)    106218.3     1   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geocorr = pandas.read_csv(\"geocorr14.csv\", encoding = \"ISO-8859-1\")[1:]\n",
    "geocorr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUMAs are unique within states but not between them, so to map them to nationally unique FIPs codes (the 'cbsa' column) we'll need to combine the 'state' and 'puma12' columns into a new field like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>puma12</th>\n",
       "      <th>cbsa</th>\n",
       "      <th>stab</th>\n",
       "      <th>cbsaname15</th>\n",
       "      <th>PUMAname</th>\n",
       "      <th>pop14</th>\n",
       "      <th>afact</th>\n",
       "      <th>stpuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>00100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AL</td>\n",
       "      <td></td>\n",
       "      <td>Lauderdale, Colbert, Franklin &amp; Marion (Northe...</td>\n",
       "      <td>39326.125</td>\n",
       "      <td>0.21</td>\n",
       "      <td>100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>00100</td>\n",
       "      <td>22520.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Florence-Muscle Shoals, AL (Metro)</td>\n",
       "      <td>Lauderdale, Colbert, Franklin &amp; Marion (Northe...</td>\n",
       "      <td>147639</td>\n",
       "      <td>0.79</td>\n",
       "      <td>100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>00200</td>\n",
       "      <td>26620.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Huntsville, AL (Metro)</td>\n",
       "      <td>Limestone &amp; Madison (Outer) Counties--Huntsvil...</td>\n",
       "      <td>183944.849</td>\n",
       "      <td>1</td>\n",
       "      <td>100200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>00301</td>\n",
       "      <td>26620.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Huntsville, AL (Metro)</td>\n",
       "      <td>Huntsville (North) &amp; Madison (East) Cities</td>\n",
       "      <td>124425.297</td>\n",
       "      <td>1</td>\n",
       "      <td>100301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01</td>\n",
       "      <td>00302</td>\n",
       "      <td>26620.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Huntsville, AL (Metro)</td>\n",
       "      <td>Huntsville City (Central &amp; South)</td>\n",
       "      <td>106218.3</td>\n",
       "      <td>1</td>\n",
       "      <td>100302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state puma12     cbsa stab                          cbsaname15  \\\n",
       "1    01  00100      NaN   AL                                       \n",
       "2    01  00100  22520.0   AL  Florence-Muscle Shoals, AL (Metro)   \n",
       "3    01  00200  26620.0   AL              Huntsville, AL (Metro)   \n",
       "4    01  00301  26620.0   AL              Huntsville, AL (Metro)   \n",
       "5    01  00302  26620.0   AL              Huntsville, AL (Metro)   \n",
       "\n",
       "                                            PUMAname       pop14  afact  \\\n",
       "1  Lauderdale, Colbert, Franklin & Marion (Northe...   39326.125  0.21    \n",
       "2  Lauderdale, Colbert, Franklin & Marion (Northe...      147639  0.79    \n",
       "3  Limestone & Madison (Outer) Counties--Huntsvil...  183944.849     1    \n",
       "4         Huntsville (North) & Madison (East) Cities  124425.297     1    \n",
       "5                  Huntsville City (Central & South)    106218.3     1    \n",
       "\n",
       "   stpuma  \n",
       "1  100100  \n",
       "2  100100  \n",
       "3  100200  \n",
       "4  100301  \n",
       "5  100302  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_stpuma(st,puma):\n",
    "    return int(str(st)+str(puma).ljust(5,'0'))\n",
    "\n",
    "geocorr['stpuma'] = geocorr.apply(lambda x: make_stpuma(x[\"state\"],x[\"puma12\"]),axis=1)\n",
    "geocorr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocorr[\"cbsa\"] = geocorr[\"cbsa\"].apply(lambda x : pandas.to_numeric(x,errors=\"coerce\"))\n",
    "\n",
    "#\n",
    "## Go through the topcoded CBSAs and make a dict for each CBSA. The keys\n",
    "## are the codes of stpumas that overlap with the CBSA, and the values are \n",
    "## Geocorr's estimate of the percentage of the PUMA's population inside \n",
    "## the CBSA. E.g. {stpuma: afact} -- we'll need these later\n",
    "#\n",
    "def get_pumas(geo_id,geo_corr):\n",
    "    cbsa = geo_corr[geo_corr[\"cbsa\"] == geo_id] \n",
    "    if len(cbsa) == 0:\n",
    "        print(geo_id)\n",
    "    target = {}\n",
    "    for index,row in cbsa.iterrows():\n",
    "        target[int(row[\"stpuma\"])] = float(row[\"afact\"])\n",
    "    return target\n",
    "\n",
    "top_coded[\"PUMAS\"] = top_coded[\"GEO.id2\"].apply(lambda x: get_pumas(x,geocorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO.id2</th>\n",
       "      <th>GEO.display-label</th>\n",
       "      <th>Upper_Limit_Bottom_20</th>\n",
       "      <th>Lower_Limit_Top_5</th>\n",
       "      <th>respop72016</th>\n",
       "      <th>PUMAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35620</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA Metro Area</td>\n",
       "      <td>25717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20275179</td>\n",
       "      <td>{3400301: 1.0, 3400302: 1.0, 3400303: 1.0, 340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31080</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA Metro Area</td>\n",
       "      <td>25626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13328261</td>\n",
       "      <td>{603701: 1.0, 603702: 1.0, 603703: 1.0, 603704...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26420</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX Metro Area</td>\n",
       "      <td>25785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6798010</td>\n",
       "      <td>{4804400: 1.0, 4804501: 1.0, 4804502: 1.0, 480...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47900</td>\n",
       "      <td>Washington-Arlington-Alexandria, DC-VA-MD-WV M...</td>\n",
       "      <td>41076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6150681</td>\n",
       "      <td>{1100101: 1.0, 1100102: 1.0, 1100103: 1.0, 110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14460</td>\n",
       "      <td>Boston-Cambridge-Newton, MA-NH Metro Area</td>\n",
       "      <td>31367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4805942</td>\n",
       "      <td>{2500400: 0.352, 2500501: 1.0, 2500502: 1.0, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GEO.id2                                  GEO.display-label  \\\n",
       "0    35620   New York-Newark-Jersey City, NY-NJ-PA Metro Area   \n",
       "1    31080      Los Angeles-Long Beach-Anaheim, CA Metro Area   \n",
       "4    26420    Houston-The Woodlands-Sugar Land, TX Metro Area   \n",
       "5    47900  Washington-Arlington-Alexandria, DC-VA-MD-WV M...   \n",
       "9    14460          Boston-Cambridge-Newton, MA-NH Metro Area   \n",
       "\n",
       "   Upper_Limit_Bottom_20  Lower_Limit_Top_5  respop72016  \\\n",
       "0                  25717                NaN     20275179   \n",
       "1                  25626                NaN     13328261   \n",
       "4                  25785                NaN      6798010   \n",
       "5                  41076                NaN      6150681   \n",
       "9                  31367                NaN      4805942   \n",
       "\n",
       "                                               PUMAS  \n",
       "0  {3400301: 1.0, 3400302: 1.0, 3400303: 1.0, 340...  \n",
       "1  {603701: 1.0, 603702: 1.0, 603703: 1.0, 603704...  \n",
       "4  {4804400: 1.0, 4804501: 1.0, 4804502: 1.0, 480...  \n",
       "5  {1100101: 1.0, 1100102: 1.0, 1100103: 1.0, 110...  \n",
       "9  {2500400: 0.352, 2500501: 1.0, 2500502: 1.0, 2...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_coded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fetch and parse PUMS data\n",
    "\n",
    "This repo has the next few steps of data collection cached, in a file named \"pums_we_want.pickle\". To do the collection from scratch, delete \"pums_we_want.pickle\". The files we source the PUMS data from are too big for\n",
    "github, but can be downloaded directly from the census:\n",
    "\n",
    "https://www.census.gov/programs-surveys/acs/data/pums.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import zipfile,requests,io,os\n",
    "\n",
    "#\n",
    "# This is a table of all the PUMAs we care to look up, and their corresponding\n",
    "# state fips and CBSA codes. It will throw errors, but they can be ignored.\n",
    "#\n",
    "relevant_pumas = geocorr[geocorr[\"cbsa\"].isin(top_coded[\"GEO.id2\"])]\n",
    "relevant_pumas[\"state\"] = relevant_pumas[\"state\"].apply(lambda x: pandas.to_numeric(x))\n",
    "relevant_pumas[\"puma12\"] = relevant_pumas[\"puma12\"].apply(lambda x: pandas.to_numeric(x))\n",
    "\n",
    "#\n",
    "# The household Census PUMS for every state in the US are available at this url: \n",
    "# https://www2.census.gov/programs-surveys/acs/data/pums/2016/1-Year/csv_hus.zip\n",
    "# The following code downloads the zip, unzips it, and deletes the irrelevant files.\n",
    "#\n",
    "def download_unzip_census(path,directory):\n",
    "    r = requests.get(path,stream=True)\n",
    "    zip_ref = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    zip_ref.extractall(directory)\n",
    "    \n",
    "#\n",
    "# Delete any files you don't want\n",
    "#\n",
    "    files = [\"ss16husa.csv\",\"ss16husb.csv\"]\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename not in files:\n",
    "            os.remove(directory+\"/\"+filename)\n",
    "\n",
    "#\n",
    "# Take out all states that aren't in our 'relevant' DataFrame, then take out \n",
    "# all PUMA codes that aren't synonymous with PUMAs in our 'relevant' DataFrame.\n",
    "#\n",
    "# This will leave in some PUMAs in the wrong state, but lets us do our make_stpuma()\n",
    "# concatenation on a much smaller subset of the data, that still includes all the \n",
    "# rows we need. Once we do that concatenation, we can zero in on exactly the \n",
    "# rows corresponding to our desired stpumas.\n",
    "#\n",
    "def filter_geos(f,relevant):\n",
    "    f = f[f[\"ST\"].isin(relevant[\"state\"].unique())]\n",
    "    f = f[f[\"PUMA\"].isin(relevant[\"puma12\"].unique())]\n",
    "    f[\"stpuma\"] = f.apply(lambda x: make_stpuma(x[\"ST\"],x[\"PUMA\"]),axis=1)\n",
    "    f = f[f[\"stpuma\"].isin(relevant[\"stpuma\"])]\n",
    "    return f\n",
    "\n",
    "#\n",
    "# If the census files aren't unzipped locally, do that. Then load the contents of \n",
    "# both csvs into a single DataFrame\n",
    "#\n",
    "def load_pums(directory,relevant):\n",
    "    if (os.path.isfile(\"too_big/pums/ss16husa.csv\") & os.path.isfile(\"too_big/pums/ss16husa.csv\")):\n",
    "        download_unzip_census(\"https://www2.census.gov/programs-surveys/acs/data/pums/2016/1-Year/csv_hus.zip\",\"too_big/pums\")\n",
    "    pums = pandas.DataFrame({})\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename[0]!='.':\n",
    "            tmp = pandas.read_csv(directory+\"/\"+filename)\n",
    "            tmp = filter_geos(tmp,relevant)\n",
    "            pums = pandas.concat([pums,tmp])\n",
    "    return pums\n",
    "\n",
    "#\n",
    "# If the pickle exists, fetch that. If not, pull the data again and pickle it. The \n",
    "# repo contains the pickle by default, so to rerun this code, delete the pickle or\n",
    "# or rename it\n",
    "#\n",
    "def pums_data(pickle_name,sourcedir,pumas_we_want):\n",
    "    if (os.path.isfile(pickle_name)):\n",
    "        return pandas.read_pickle(pickle_name,\"gzip\")\n",
    "    pums_we_want = load_pums(sourcedir,pumas_we_want)\n",
    "    pums_we_want.to_pickle(pickle_name,\"gzip\")\n",
    "    \n",
    "pums_we_want = pums_data(\"pums_we_want.pickle\",\"too_big/pums/\",relevant_pumas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate weighted data\n",
    "\n",
    "Now we have all the PUMS data for every geography we care about. This dataframe has a column \"WGTP\" which indicates how many households each particular record represents. In order to get accurate percentiles, we need each row to represent a single household. We're going to convert the data by duplicating each row n times, where n equals the row's WGTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
