{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Income by Quantile Over Time\n",
    "\n",
    "The recovery from the recession has looked very different for the bottom earners and the top-earners. And it's been very different in Bridgeport than it was nationally. In order to illustrate this, we made a graphic to track the percent change in mean income for four groups:\n",
    "\n",
    "1.A The bottom 20% of income-earners in Bridgeport\n",
    "1.B The top 5% of income-earners in Bridgeport\n",
    "2.A The bottom 20% of income-earners nationally\n",
    "2.B The top 20% of income-earners nationally\n",
    "\n",
    "### ACS API\n",
    "\n",
    "The mean income for each of these groups is available from the Census API from 2012-2016. We want the 1 year version of the American Commmunity Survey. Details on the API use can be found here: https://www.census.gov/data/developers/data-sets/acs-1year.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas,json,urllib,re,numpy,time\n",
    "\n",
    "# API base url\n",
    "base = \"https://api.census.gov/data/\"\n",
    "\n",
    "#\n",
    "# B19081_001E = mean income for the bottom 20% of income earners\n",
    "# B19081_006E = mean income for the top 5% of income earners\n",
    "#\n",
    "fields = [\"B19081_001E\",\"B19081_006E\"]\n",
    "\n",
    "# Build a url for the given year, geography type, code, and fields\n",
    "def construct_quant_url(year,geo_type,geo_code,quants):\n",
    "    url = base + str(year)\n",
    "    \n",
    "    # The url structure is different for 2016 than it is for the other years because ¯\\_(ツ)_/¯\n",
    "    if (year == 2016):\n",
    "        url += \"/acs\"\n",
    "    url += \"/acs1?get=\"\n",
    "    for q in quants:\n",
    "        url += q+\"&\"\n",
    "    url+= \"for=\"+geo_type\n",
    "    if geo_code!='':\n",
    "        url+=(\":\"+geo_code)\n",
    "    return(url)\n",
    "\n",
    "# Request & load data from a url\n",
    "def url_to_data(url):\n",
    "    req = urllib.request.Request(url)\n",
    "    res = urllib.request.urlopen(req)\n",
    "    data = json.load(res)\n",
    "    return data\n",
    "\n",
    "# Gets the API data and formats it as a list of lists.\n",
    "#\n",
    "# Sample output for make_long_data(2012,2014,'us','',quants=fields)\n",
    "#\n",
    "# [['B19081_001E', 'B19081_006E', 'geo', 'year'],\n",
    "# ['11361', '319918', '1', 2012],\n",
    "# ['11544', '339950', '1', 2013],\n",
    "# ['11859', '346522', '1', 2014]]\n",
    "#\n",
    "def make_long_data(min_year,max_year,geo_type,geo_code,quants):\n",
    "    tar = [fields+[\"geo\",\"year\"]]\n",
    "    for year in range(min_year,max_year+1):\n",
    "        url = construct_quant_url(year,geo_type,geo_code,quants)\n",
    "        new_row = url_to_data(url)[1]\n",
    "        new_row.append(year)\n",
    "        tar.append(new_row)\n",
    "    return tar\n",
    "\n",
    "# Get data for our fields 2012-2016, for Bridgeport's MSA -- fips code 14860\n",
    "bridgeport_data = make_long_data(2012,2016,\"metropolitan%20statistical%20area/micropolitan%20statistical%20area\",\"14860\",fields)\n",
    "\n",
    "# Get data for our fields 2012-2016, nationally -- don't need a fips code\n",
    "national_data = make_long_data(2012,2016,\"us\",\"\",fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bridgeport_data)\n",
    "bp_df = pandas.DataFrame(bridgeport_data[1:],columns = bridgeport_data[0])\n",
    "nat_df = pandas.DataFrame(national_data[1:],columns = national_data[0])\n",
    "\n",
    "bp_df = bp_df.rename(columns={\"B19081_001E\":\"20\",\"B19081_006E\":\"95\"})\n",
    "nat_df = nat_df.rename(columns={\"B19081_001E\":\"20\",\"B19081_006E\":\"95\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earlier Years\n",
    "\n",
    "We want data going back to 2007. Luckily, the Census collected these numbers. Unluckily, they're not available through the API. We went through and found [TABLE TITLE] from American Fact-Finder for 2007-2011 (5 tables), downloaded the spreadsheets, and "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
